{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Privacy-Preserving Federated Vision Transformers for Pneumonia Detection on Chest X-Rays\n",
        "\n",
        "This notebook implements a federated learning framework using Vision Transformers (ViT) for pneumonia classification on chest X-ray images under non-IID data distribution.\n",
        "Differentially Private Federated Learning (DP-FL) is implemented in selected experiments using DP-SGD with explicit privacy budgets (ε).\n"
      ],
      "metadata": {
        "id": "DgSM9cOXT7ha"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Project Overview\n",
        "\n",
        "This project explores privacy-aware federated learning for medical image classification.\n",
        "Instead of centralizing sensitive chest X-ray data, model training is performed across multiple simulated clients, each holding local, non-identically distributed (non-IID) data.\n",
        "\n",
        "The objective is to evaluate the robustness of Vision Transformers in a federated setting for pneumonia detection.\n"
      ],
      "metadata": {
        "id": "GXy8EJdQUTHy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Environment Setup and Dependencies\n",
        "\n",
        "This section defines the required Python libraries and deep learning frameworks used in the project.\n",
        "The implementation is framework-agnostic and can be executed locally or in cloud environments such as Google Colab.\n"
      ],
      "metadata": {
        "id": "X_zeK6tBGNZa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "p56gDC5EEomI"
      },
      "outputs": [],
      "source": [
        "!pip install timm kagglehub opacus\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "import kagglehub\n",
        "\n",
        "from opacus import PrivacyEngine\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Dataset Description and Preprocessing\n",
        "\n",
        "A publicly available chest X-ray dataset is used for binary classification (Pneumonia vs Normal).\n",
        "Standard preprocessing steps such as resizing, normalization, and data augmentation are applied to ensure consistency across clients.\n"
      ],
      "metadata": {
        "id": "e8py0GicGVXJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download latest version of Chest X-Ray Pneumonia dataset\n",
        "path = kagglehub.dataset_download(\"paultimothymooney/chest-xray-pneumonia\")\n",
        "\n",
        "print(\"Root path:\", path)\n",
        "print(\"Contents:\", os.listdir(path))\n",
        "\n",
        "data_root = os.path.join(path, \"chest_xray\")\n",
        "print(\"Data root:\", data_root)\n",
        "print(\"Data root contents:\", os.listdir(data_root))\n"
      ],
      "metadata": {
        "id": "CdBGNcyVFh3s",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Transforms and dataset objects**"
      ],
      "metadata": {
        "id": "ha5qgB9bGaYo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_size = 224\n",
        "\n",
        "train_tfms = transforms.Compose([\n",
        "    transforms.Resize((img_size, img_size)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "])\n",
        "\n",
        "test_tfms = transforms.Compose([\n",
        "    transforms.Resize((img_size, img_size)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "])\n",
        "\n",
        "train_ds_full = datasets.ImageFolder(os.path.join(data_root, \"train\"), transform=train_tfms)\n",
        "val_ds        = datasets.ImageFolder(os.path.join(data_root, \"val\"),   transform=test_tfms)\n",
        "test_ds       = datasets.ImageFolder(os.path.join(data_root, \"test\"),  transform=test_tfms)\n",
        "\n",
        "print(\"Train size:\", len(train_ds_full))\n",
        "print(\"Val size:  \", len(val_ds))\n",
        "print(\"Test size: \", len(test_ds))\n",
        "print(\"Classes:   \", train_ds_full.classes)  # should be ['NORMAL', 'PNEUMONIA']\n"
      ],
      "metadata": {
        "id": "rTbhNVogFmTa",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Non-IID Client Data Partitioning\n",
        "\n",
        "To simulate real-world clinical scenarios, the dataset is partitioned across multiple federated clients using a non-IID strategy.\n",
        "Each client contains a distinct class distribution, reflecting data heterogeneity commonly observed across hospitals and medical institutions.\n",
        "\n",
        "\n",
        "NON-IID client splits:\n",
        "\n",
        "Client 1: pneumonia-heavy\n",
        "\n",
        "Client 2: normal-heavy\n",
        "\n",
        "Client 3: remaining mixed"
      ],
      "metadata": {
        "id": "SZP8bDZOGeo-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build indices per class for non-IID split\n",
        "class_to_indices = defaultdict(list)\n",
        "for idx, (_, label) in enumerate(train_ds_full.samples):\n",
        "    class_to_indices[label].append(idx)\n",
        "\n",
        "normal_indices = np.array(class_to_indices[0])  # label 0 = NORMAL\n",
        "pneu_indices   = np.array(class_to_indices[1])  # label 1 = PNEUMONIA\n",
        "\n",
        "np.random.shuffle(normal_indices)\n",
        "np.random.shuffle(pneu_indices)\n",
        "\n",
        "num_normal = len(normal_indices)\n",
        "num_pneu   = len(pneu_indices)\n",
        "\n",
        "print(\"Total NORMAL:\", num_normal)\n",
        "print(\"Total PNEUMONIA:\", num_pneu)\n",
        "\n",
        "# Client 1: pneumonia-heavy\n",
        "c1_pneu = int(0.5 * num_pneu)      # ~50% of pneumonia cases\n",
        "c1_norm = int(0.1 * num_normal)    # small subset of normals\n",
        "\n",
        "# Client 2: normal-heavy\n",
        "c2_pneu = int(0.1 * num_pneu)\n",
        "c2_norm = int(0.5 * num_normal)\n",
        "\n",
        "# Remaining for Client 3\n",
        "used_norm = c1_norm + c2_norm\n",
        "used_pneu = c1_pneu + c2_pneu\n",
        "\n",
        "c3_norm_indices = normal_indices[used_norm:]\n",
        "c3_pneu_indices = pneu_indices[used_pneu:]\n",
        "\n",
        "c1_indices = np.concatenate([pneu_indices[:c1_pneu], normal_indices[:c1_norm]])\n",
        "c2_indices = np.concatenate([\n",
        "    pneu_indices[c1_pneu:c1_pneu + c2_pneu],\n",
        "    normal_indices[c1_norm:c1_norm + c2_norm]\n",
        "])\n",
        "c3_indices = np.concatenate([c3_pneu_indices, c3_norm_indices])\n",
        "\n",
        "np.random.shuffle(c1_indices)\n",
        "np.random.shuffle(c2_indices)\n",
        "np.random.shuffle(c3_indices)\n",
        "\n",
        "client_indices = [c1_indices, c2_indices, c3_indices]\n",
        "client_datasets = [Subset(train_ds_full, idxs) for idxs in client_indices]\n",
        "\n",
        "for i, idxs in enumerate(client_indices):\n",
        "    labels = [train_ds_full.samples[j][1] for j in idxs]\n",
        "    n_norm = sum(1 for l in labels if l == 0)\n",
        "    n_pneu = sum(1 for l in labels if l == 1)\n",
        "    print(f\"Client {i}: total={len(idxs)}, NORMAL={n_norm}, PNEUMONIA={n_pneu}\")\n"
      ],
      "metadata": {
        "id": "DVYW9z7lFry9",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DataLoaders for clients, val, test**"
      ],
      "metadata": {
        "id": "EJWgp3vlGuzR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "client_loaders = [\n",
        "    DataLoader(cd, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "    for cd in client_datasets\n",
        "]\n",
        "\n",
        "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n"
      ],
      "metadata": {
        "id": "MHwfr2OZFx8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Vision Transformer Model Architecture\n",
        "\n",
        "A Vision Transformer (ViT) architecture is employed to model global contextual relationships within chest X-ray images.\n",
        "The model is adapted for binary classification and serves as the base learner across all federated clients.\n",
        "\n",
        "\n",
        "**ViT model, training & evaluation helpers**"
      ],
      "metadata": {
        "id": "SRz-KYG3Gyds"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import timm\n",
        "\n",
        "def create_vit_model():\n",
        "    model = timm.create_model(\"vit_tiny_patch16_224\", pretrained=True)\n",
        "    in_features = model.head.in_features\n",
        "    model.head = nn.Linear(in_features, 2)\n",
        "    return model.to(device)\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, criterion):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for imgs, labels in loader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(imgs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * imgs.size(0)\n",
        "\n",
        "    return total_loss / len(loader.dataset)\n",
        "\n",
        "def evaluate(model, loader, criterion):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    all_preds, all_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in loader:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            outputs = model(imgs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item() * imgs.size(0)\n",
        "\n",
        "            preds = outputs.argmax(dim=1).detach().cpu().numpy()\n",
        "            all_preds.extend(preds)\n",
        "            all_labels.extend(labels.detach().cpu().numpy())\n",
        "\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    prec, rec, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='binary')\n",
        "    return total_loss / len(loader.dataset), acc, prec, rec, f1\n"
      ],
      "metadata": {
        "id": "tPm1Zd0yF0T_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Federated Learning Framework\n",
        "\n",
        "Federated learning is implemented by iteratively training local models on client-specific data and aggregating model parameters at a central server.\n",
        "This framework ensures that raw medical images remain localized at each client throughout the training process.\n",
        "\n",
        "\n",
        "**FedAvg helper functions**"
      ],
      "metadata": {
        "id": "P7o_GK0RG2Hn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model_weights(model):\n",
        "    raw_state = model.state_dict()\n",
        "    clean_state = {}\n",
        "    for k, v in raw_state.items():\n",
        "        if k.startswith(\"_module.\"):\n",
        "            new_key = k[len(\"_module.\"):]\n",
        "        else:\n",
        "            new_key = k\n",
        "        clean_state[new_key] = v.detach().cpu().clone()\n",
        "    return clean_state\n",
        "\n",
        "\n",
        "def set_model_weights(model, weights):\n",
        "    model.load_state_dict(weights)\n",
        "\n",
        "def average_weights(weights_list):\n",
        "    avg = {}\n",
        "    for k in weights_list[0].keys():\n",
        "        stacked = torch.stack([w[k] for w in weights_list], dim=0)\n",
        "        avg[k] = stacked.mean(dim=0)\n",
        "    return avg\n"
      ],
      "metadata": {
        "id": "TVfwB0PKF4Xw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Experiment 1: Centralized baseline**"
      ],
      "metadata": {
        "id": "42X_Irh-G51g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "central_model = create_vit_model()\n",
        "optimizer = optim.Adam(central_model.parameters(), lr=1e-4)\n",
        "\n",
        "central_history = {\"epoch\": [], \"val_acc\": [], \"val_f1\": []}\n",
        "\n",
        "num_epochs = 5\n",
        "\n",
        "central_train_loader = DataLoader(\n",
        "    train_ds_full, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True\n",
        ")\n",
        "\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    train_loss = train_one_epoch(central_model, central_train_loader, optimizer, criterion)\n",
        "    val_loss, acc, prec, rec, f1 = evaluate(central_model, val_loader, criterion)\n",
        "    central_history[\"epoch\"].append(epoch)\n",
        "    central_history[\"val_acc\"].append(acc)\n",
        "    central_history[\"val_f1\"].append(f1)\n",
        "\n",
        "    print(f\"[Central] Epoch {epoch:02d}: train_loss={train_loss:.4f}, \"\n",
        "          f\"val_acc={acc:.4f}, val_f1={f1:.4f}\")\n",
        "\n",
        "central_test_loss, central_test_acc, central_test_prec, central_test_rec, central_test_f1 = \\\n",
        "    evaluate(central_model, test_loader, criterion)\n",
        "\n",
        "print(\"\\n[Centralized ViT] Test results:\")\n",
        "print(f\"  loss={central_test_loss:.4f}, acc={central_test_acc:.4f}, \"\n",
        "      f\"prec={central_test_prec:.4f}, rec={central_test_rec:.4f}, \"\n",
        "      f\"f1={central_test_f1:.4f}\")\n",
        "\n",
        "torch.save(central_model.state_dict(), \"/content/central_vit.pth\")"
      ],
      "metadata": {
        "id": "UdQk4ExbGFcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Experiment 2: Federated ViT on NON-IID (no DP)**"
      ],
      "metadata": {
        "id": "5cw3gMNDKsj3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rounds = 5\n",
        "local_epochs = 5\n",
        "lr = 1e-4\n",
        "\n",
        "global_model = create_vit_model()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "fed_history = {\"round\": [], \"val_acc\": [], \"val_f1\": []}\n",
        "\n",
        "for r in range(1, rounds + 1):\n",
        "    print(f\"\\n=== Federated Round {r} (non-DP) ===\")\n",
        "    client_weights = []\n",
        "\n",
        "    for cid, loader in enumerate(client_loaders):\n",
        "        print(f\"  Client {cid}:\")\n",
        "        client_model = create_vit_model()\n",
        "        set_model_weights(client_model, get_model_weights(global_model))\n",
        "\n",
        "        optimizer = optim.Adam(client_model.parameters(), lr=lr)\n",
        "\n",
        "        for e in range(1, local_epochs + 1):\n",
        "            train_loss = train_one_epoch(client_model, loader, optimizer, criterion)\n",
        "            print(f\"    local_epoch {e}: loss={train_loss:.4f}\")\n",
        "\n",
        "        client_weights.append(get_model_weights(client_model))\n",
        "        del client_model\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    new_global_weights = average_weights(client_weights)\n",
        "    set_model_weights(global_model, new_global_weights)\n",
        "\n",
        "    val_loss, acc, prec, rec, f1 = evaluate(global_model, val_loader, criterion)\n",
        "    fed_history[\"round\"].append(r)\n",
        "    fed_history[\"val_acc\"].append(acc)\n",
        "    fed_history[\"val_f1\"].append(f1)\n",
        "\n",
        "    print(f\"[Global after round {r}] val_acc={acc:.4f}, val_f1={f1:.4f}\")\n",
        "\n",
        "fl_nondp_test_loss, fl_nondp_test_acc, fl_nondp_test_prec, fl_nondp_test_rec, fl_nondp_test_f1 = \\\n",
        "    evaluate(global_model, test_loader, criterion)\n",
        "\n",
        "print(\"\\n[Federated ViT (non-DP, non-IID)] Test results:\")\n",
        "print(f\"  loss={fl_nondp_test_loss:.4f}, acc={fl_nondp_test_acc:.4f}, \"\n",
        "      f\"prec={fl_nondp_test_prec:.4f}, rec={fl_nondp_test_rec:.4f}, \"\n",
        "      f\"f1={fl_nondp_test_f1:.4f}\")\n",
        "\n",
        "torch.save(global_model.state_dict(), \"/content/fed_vit.pth\")"
      ],
      "metadata": {
        "id": "amTuZ2gRKni_",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Helper for DP-SGD Optimizer per client**"
      ],
      "metadata": {
        "id": "l8y4SNAHSxGg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_dp_client(model, loader, lr, local_epochs, target_epsilon, target_delta=1e-5, max_grad_norm=1.0):\n",
        "    \"\"\"\n",
        "    Wraps model, optimizer, and DataLoader with Opacus DP-SGD for a given target epsilon.\n",
        "    \"\"\"\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "    privacy_engine = PrivacyEngine()\n",
        "\n",
        "    model, optimizer, dp_loader = privacy_engine.make_private_with_epsilon(\n",
        "        module=model,\n",
        "        optimizer=optimizer,\n",
        "        data_loader=loader,\n",
        "        epochs=local_epochs,\n",
        "        target_epsilon=target_epsilon,\n",
        "        target_delta=target_delta,\n",
        "        max_grad_norm=max_grad_norm,\n",
        "    )\n",
        "\n",
        "    return model, optimizer, dp_loader, privacy_engine\n"
      ],
      "metadata": {
        "id": "O8EPhTr9Smp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Experiment 3: DP-FL for ε = 8, 3, 1**"
      ],
      "metadata": {
        "id": "3jCxasouSzQf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epsilons = [8.0, 3.0, 1.0]\n",
        "dp_results = {}\n",
        "\n",
        "for target_eps in epsilons:\n",
        "    print(f\"\\n\\n==============================\")\n",
        "    print(f\" DP-FL RUN for target epsilon = {target_eps}\")\n",
        "    print(f\"==============================\")\n",
        "\n",
        "    global_model = create_vit_model()\n",
        "    dp_history = {\"round\": [], \"val_acc\": [], \"val_f1\": []}\n",
        "\n",
        "    for r in range(1, rounds + 1):\n",
        "        print(f\"\\n=== DP Federated Round {r} (target eps={target_eps}) ===\")\n",
        "        client_weights = []\n",
        "\n",
        "        for cid, loader in enumerate(client_loaders):\n",
        "            print(f\"  Client {cid}:\")\n",
        "            client_model = create_vit_model()\n",
        "            set_model_weights(client_model, get_model_weights(global_model))\n",
        "\n",
        "            # Make client DP\n",
        "            client_model, optimizer, dp_loader, privacy_engine = make_dp_client(\n",
        "                client_model, loader, lr=lr, local_epochs=local_epochs,\n",
        "                target_epsilon=target_eps, target_delta=1e-5, max_grad_norm=1.0\n",
        "            )\n",
        "\n",
        "            for e in range(1, local_epochs + 1):\n",
        "                train_loss = train_one_epoch(client_model, dp_loader, optimizer, criterion)\n",
        "                print(f\"    local_epoch {e}: loss={train_loss:.4f}\")\n",
        "\n",
        "            eps_spent = privacy_engine.get_epsilon(delta=1e-5)\n",
        "            print(f\"    Approx epsilon spent so far (client {cid}): {eps_spent:.2f}\")\n",
        "\n",
        "            client_weights.append(get_model_weights(client_model))\n",
        "            del client_model, optimizer, dp_loader, privacy_engine\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        new_global_weights = average_weights(client_weights)\n",
        "        set_model_weights(global_model, new_global_weights)\n",
        "\n",
        "        val_loss, acc, prec, rec, f1 = evaluate(global_model, val_loader, criterion)\n",
        "        dp_history[\"round\"].append(r)\n",
        "        dp_history[\"val_acc\"].append(acc)\n",
        "        dp_history[\"val_f1\"].append(f1)\n",
        "\n",
        "        print(f\"[Global after round {r} | DP eps={target_eps}] val_acc={acc:.4f}, val_f1={f1:.4f}\")\n",
        "\n",
        "    # After all rounds for this epsilon, evaluate on test set\n",
        "    test_loss, test_acc, test_prec, test_rec, test_f1 = evaluate(global_model, test_loader, criterion)\n",
        "\n",
        "    print(f\"\\n[DP-FL ViT] target eps={target_eps} | Test results:\")\n",
        "    print(f\"  loss={test_loss:.4f}, acc={test_acc:.4f}, \"\n",
        "          f\"prec={test_prec:.4f}, rec={test_rec:.4f}, f1={test_f1:.4f}\")\n",
        "\n",
        "    dp_results[target_eps] = {\n",
        "        \"test_loss\": test_loss,\n",
        "        \"test_acc\": test_acc,\n",
        "        \"test_prec\": test_prec,\n",
        "        \"test_rec\": test_rec,\n",
        "        \"test_f1\": test_f1,\n",
        "        \"val_acc_per_round\": dp_history[\"val_acc\"],\n",
        "        \"val_f1_per_round\": dp_history[\"val_f1\"]\n",
        "    }\n",
        "\n",
        "    # ✅ Save the final global model for this epsilon\n",
        "    if target_eps == 3.0:\n",
        "        torch.save(global_model.state_dict(), \"/content/dp_vit_eps3.pth\")\n",
        "        print(\"Saved DP-FL model for eps=3.0 to /content/dp_vit_eps3.pth\")\n",
        "    elif target_eps == 1.0:\n",
        "        torch.save(global_model.state_dict(), \"/content/dp_vit_eps1.pth\")\n",
        "        print(\"Saved DP-FL model for eps=1.0 to /content/dp_vit_eps1.pth\")\n",
        "    elif target_eps == 8.0:\n",
        "        torch.save(global_model.state_dict(), \"/content/dp_vit_eps8.pth\")\n",
        "        print(\"Saved DP-FL model for eps=8.0 to /content/dp_vit_eps8.pth\")\n"
      ],
      "metadata": {
        "id": "tRtYwBlXStTh",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experimental Results and Observations\n",
        "\n",
        "The experimental results highlight the feasibility of training Vision Transformers in a federated learning environment.\n",
        "Observed performance trends across communication rounds provide insights into convergence behavior under data heterogeneity.\n"
      ],
      "metadata": {
        "id": "nlbqrHZMaZyZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n========== SUMMARY ==========\\n\")\n",
        "print(\"Centralized ViT:\")\n",
        "print(f\"  acc={central_test_acc:.4f}, f1={central_test_f1:.4f}\")\n",
        "\n",
        "print(\"\\nNon-DP Federated ViT (non-IID):\")\n",
        "print(f\"  acc={fl_nondp_test_acc:.4f}, f1={fl_nondp_test_f1:.4f}\")\n",
        "\n",
        "for eps in epsilons:\n",
        "    r = dp_results[eps]\n",
        "    print(f\"\\nDP-FL ViT (target eps={eps}):\")\n",
        "    print(f\"  acc={r['test_acc']:.4f}, f1={r['test_f1']:.4f}, \"\n",
        "          f\"prec={r['test_prec']:.4f}, rec={r['test_rec']:.4f}\")\n"
      ],
      "metadata": {
        "id": "5zaTZZbtw8Sd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# ===== FINAL METRICS FROM LATEST RUN =====\n",
        "methods = [\n",
        "    \"Centralized\",\n",
        "    \"Federated\",\n",
        "    \"DP-FL (ε=8.0)\",\n",
        "    \"DP-FL (ε=3.0)\",\n",
        "    \"DP-FL (ε=1.0)\"\n",
        "]\n",
        "\n",
        "accuracy = np.array([0.8029, 0.8333, 0.7821, 0.6490, 0.7308])\n",
        "precision = np.array([0.7613, 0.7907, 0.8068, 0.6472, 0.7185])\n",
        "recall    = np.array([0.9974, 0.9974, 0.8564, 0.9641, 0.9359])\n",
        "f1_scores = np.array([0.8635, 0.8821, 0.8308, 0.7745, 0.8129])\n",
        "\n",
        "# For privacy–utility curve (only DP-FL runs)\n",
        "epsilons = np.array([8.0, 3.0, 1.0])\n",
        "acc_dp   = np.array([0.7821, 0.6490, 0.7308])\n",
        "f1_dp    = np.array([0.8308, 0.7745, 0.8129])\n",
        "\n",
        "# ===== FIGURE 1: Accuracy comparison =====\n",
        "plt.figure()\n",
        "plt.bar(methods, accuracy)\n",
        "plt.ylim(0, 1.0)\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Accuracy Comparison Across Methods\")\n",
        "plt.xticks(rotation=25)\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"fig_accuracy.png\", dpi=300)\n",
        "plt.close()\n",
        "\n",
        "# ===== FIGURE 2: F1-score comparison =====\n",
        "plt.figure()\n",
        "plt.bar(methods, f1_scores)\n",
        "plt.ylim(0, 1.0)\n",
        "plt.ylabel(\"F1 Score\")\n",
        "plt.title(\"F1-Score Comparison Across Methods\")\n",
        "plt.xticks(rotation=25)\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"fig_f1score.png\", dpi=300)\n",
        "plt.close()\n",
        "\n",
        "# ===== FIGURE 3: Privacy–performance trade-off (ε vs F1 & Acc) =====\n",
        "plt.figure()\n",
        "plt.plot(epsilons, acc_dp, marker=\"o\", linestyle=\"-\", label=\"Accuracy\")\n",
        "plt.plot(epsilons, f1_dp,  marker=\"s\", linestyle=\"--\", label=\"F1 Score\")\n",
        "plt.ylim(0, 1.0)\n",
        "plt.xlabel(\"Privacy Budget (ε)\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.title(\"Privacy–Performance Trade-off for DP-FL ViT\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"fig_privacy_tradeoff.png\", dpi=300)\n",
        "plt.close()\n",
        "\n",
        "print(\"Saved: fig_accuracy.png, fig_f1score.png, fig_privacy_tradeoff.png\")\n"
      ],
      "metadata": {
        "id": "P6wQ1tKgnbXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 1) Helper: load model from checkpoint using existing create_vit_model()\n",
        "def load_model_from_ckpt(path):\n",
        "    model = create_vit_model()  # same as in training\n",
        "    state = torch.load(path, map_location=device)\n",
        "    model.load_state_dict(state)\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "central_model = load_model_from_ckpt(\"/content/central_vit.pth\")\n",
        "fed_model     = load_model_from_ckpt(\"/content/fed_vit.pth\")\n",
        "dp_model      = load_model_from_ckpt(\"/content/dp_vit_eps3.pth\")  # eps = 3.0\n",
        "\n",
        "# 2) Get one pneumonia image from the test set\n",
        "pneumonia_label = 1  # adjust if Pneumonia != 1 in code\n",
        "pneumonia_img = None\n",
        "\n",
        "for images, labels in test_loader:\n",
        "    idx = (labels == pneumonia_label).nonzero(as_tuple=True)[0]\n",
        "    if len(idx) > 0:\n",
        "        i = idx[0].item()\n",
        "        pneumonia_img = images[i]  # [C,H,W]\n",
        "        break\n",
        "\n",
        "if pneumonia_img is None:\n",
        "    raise RuntimeError(\"Could not find a pneumonia sample in test_loader!\")\n",
        "\n",
        "# 3) Saliency map generator (gradient-based)\n",
        "def generate_saliency_heatmap(model, image_tensor, target_class=1):\n",
        "    \"\"\"\n",
        "    image_tensor: [C, H, W], normalized, on CPU\n",
        "    target_class: index of pneumonia class\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    x = image_tensor.unsqueeze(0).to(device)  # [1, C, H, W]\n",
        "    x.requires_grad_(True)\n",
        "\n",
        "    with torch.enable_grad():\n",
        "        logits = model(x)          # [1, num_classes]\n",
        "        score = logits[0, target_class]\n",
        "\n",
        "    model.zero_grad()\n",
        "    score.backward()\n",
        "    grad = x.grad.detach().cpu().numpy()[0]  # [C,H,W]\n",
        "\n",
        "    saliency = np.mean(np.abs(grad), axis=0)\n",
        "    saliency -= saliency.min()\n",
        "    if saliency.max() > 0:\n",
        "        saliency /= saliency.max()\n",
        "    return saliency  # [H,W] in [0,1]\n",
        "\n",
        "# 4) Denormalize for visualization (adjust if used different mean/std)\n",
        "imagenet_mean = np.array([0.485, 0.456, 0.406]).reshape(3,1,1)\n",
        "imagenet_std  = np.array([0.229, 0.224, 0.225]).reshape(3,1,1)\n",
        "\n",
        "img_np = pneumonia_img.numpy()\n",
        "img_denorm = (img_np * imagenet_std + imagenet_mean)\n",
        "img_denorm = np.clip(img_denorm, 0.0, 1.0)\n",
        "img_gray = img_denorm.mean(axis=0)  # HxW grayscale-ish\n",
        "\n",
        "# 5) Generate saliency for 3 models\n",
        "sal_central = generate_saliency_heatmap(central_model, pneumonia_img, target_class=pneumonia_label)\n",
        "sal_fed     = generate_saliency_heatmap(fed_model,     pneumonia_img, target_class=pneumonia_label)\n",
        "sal_dp      = generate_saliency_heatmap(dp_model,      pneumonia_img, target_class=pneumonia_label)\n",
        "\n",
        "# 6) Plot triptych\n",
        "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
        "titles = [\"Centralized ViT\", \"Federated ViT\", \"DP-FL ViT (ε=3.0)\"]\n",
        "sal_maps = [sal_central, sal_fed, sal_dp]\n",
        "\n",
        "for ax, title, sal in zip(axes, titles, sal_maps):\n",
        "    ax.imshow(img_gray, cmap=\"gray\")\n",
        "    ax.imshow(sal, cmap=\"jet\", alpha=0.5)\n",
        "    ax.set_title(title)\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"attention_triptych.png\", dpi=300, bbox_inches=\"tight\")\n",
        "plt.close()\n",
        "\n",
        "print(\"Saved: attention_triptych.png\")\n"
      ],
      "metadata": {
        "id": "x007lLz2oSQX",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Limitations and Future Directions\n",
        "\n",
        "This implementation focuses on simulated federated learning and does not include formal differential privacy guarantees or secure aggregation protocols.\n",
        "Future work may explore integrating differential privacy, secure aggregation, and real-world federated deployment scenarios.\n"
      ],
      "metadata": {
        "id": "EyiBjJOaamKP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Privacy Considerations:\n",
        "\n",
        "This work implements formally differentially private federated learning using DP-SGD via the Opacus library.\n",
        "Per-sample gradients are clipped and perturbed with Gaussian noise, and privacy budgets (ε) are explicitly\n",
        "computed using a Rényi Differential Privacy accountant in Experiments 3 and 4.\n",
        "These mechanisms provide formal client-level differential privacy guarantees against gradient-based\n",
        "inference attacks under the stated experimental assumptions."
      ],
      "metadata": {
        "id": "ORaDKMYFaq44"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Disclaimer\n",
        "\n",
        "This project is intended solely for academic and educational purposes.\n",
        "It is not a clinical decision-support system and should not be used for medical diagnosis or treatment.\n"
      ],
      "metadata": {
        "id": "Xxr3u9YwauBy"
      }
    }
  ]
}